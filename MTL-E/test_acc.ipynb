{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/nlp/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which model are you testing\n",
    "model_name = \"albert-xxlarge-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, task_name):\n",
    "    # Load the configuration\n",
    "    config_path = f\"MTL-E/{task_name}_model/{model_name}/config.json\"\n",
    "    config = transformers.AutoConfig.from_pretrained(config_path)\n",
    "\n",
    "    # Load the model state dict\n",
    "    model_path = f\"MTL-E/{task_name}_model/{model_name}/pytorch_model.bin\"\n",
    "    model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "        pretrained_model_name_or_path=None,\n",
    "        config=config,\n",
    "        state_dict=torch.load(model_path)\n",
    "    )\n",
    "\n",
    "    # Load the tokenizer\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(f\"MTL-E/{task_name}_model/{model_name}\")\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load test data from CSV\n",
    "def load_test_data(csv_path):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, test_data, batch_size=8):\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    for i in range(0, len(test_data), batch_size):\n",
    "        batch_data = test_data.iloc[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_data['Sentence'].tolist(), max_length=128, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        labels = torch.tensor(batch_data['labels'].tolist())\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "        \n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        true_list.extend(labels.cpu().numpy())\n",
    "        pred_list.extend(predictions)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    conf_matrix = confusion_matrix(true_list, pred_list)\n",
    "    class_report = classification_report(true_list, pred_list, output_dict=True)\n",
    "    \n",
    "    return conf_matrix, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Sentence  identity_attack_x  \\\n",
      "0     As someone pointed out earlier ISIS and radic...           0.800000   \n",
      "1     URL bellamycharlottesvilletwitter  Read up on...           0.506024   \n",
      "2    . . .  she wants to give other women of color ...           0.500000   \n",
      "3    . The whole world hates the white world yet th...           0.500000   \n",
      "4    ... what horrible human beings .... pathetic. ...           0.653333   \n",
      "..                                                 ...                ...   \n",
      "645  Youre right he should pick something else to b...           0.500000   \n",
      "646  Youre right the international condemnation of ...           0.700000   \n",
      "647  Youre the one making claims.  I called you on ...           0.600000   \n",
      "648  Youre white so clearly you dont understand or ...           0.800000   \n",
      "649  Yup I keep telling people people like you are ...           0.636364   \n",
      "\n",
      "     labels          target       category  \\\n",
      "0         1  muslims,whites  religion,race   \n",
      "1         0             NaN           none   \n",
      "2         1          whites    race,gender   \n",
      "3         1          whites           race   \n",
      "4         1      christians       religion   \n",
      "..      ...             ...            ...   \n",
      "645       1          whites           race   \n",
      "646       1            jews       religion   \n",
      "647       1            gays          lgbtq   \n",
      "648       1          whites           race   \n",
      "649       1          blacks           race   \n",
      "\n",
      "                                rationale   id  \n",
      "0    prejudice against whites and muslims    1  \n",
      "1                                     NaN    2  \n",
      "2             prejudice against white men    3  \n",
      "3                prejudice against whites    4  \n",
      "4            prejudice against christians    5  \n",
      "..                                    ...  ...  \n",
      "645              prejudice against whites  646  \n",
      "646                prejudice against jews  647  \n",
      "647                prejudice towards gays  648  \n",
      "648              prejudice against whites  649  \n",
      "649              prejudice against blacks  650  \n",
      "\n",
      "[650 rows x 7 columns]\n",
      "Evaluating bias model...\n",
      "---------------------------------Confusion Matrix------------------------------------\n",
      "    0    1\n",
      "0  38   93\n",
      "1  58  461\n",
      "---------------------------------Evaluation Metrics------------------------------------\n",
      "              precision    recall  f1-score     support\n",
      "0              0.395833  0.290076  0.334802  131.000000\n",
      "1              0.832130  0.888247  0.859273  519.000000\n",
      "accuracy       0.767692  0.767692  0.767692    0.767692\n",
      "macro avg      0.613982  0.589161  0.597037  650.000000\n",
      "weighted avg   0.744199  0.767692  0.753572  650.000000\n",
      "                                               Sentence  labels    id\n",
      "0                             She hailed Mother Russia.       1     1\n",
      "1     The mover will be here soon. They don't really...       1     2\n",
      "2     He was being hateful to the server and demandi...       1     3\n",
      "3     In TLC's 90 DAY FIANCE one of the couples was ...       1     4\n",
      "4                   He wore pants that showed his crack       1     5\n",
      "...                                                 ...     ...   ...\n",
      "1694            She was very understanding and flexible       0  1695\n",
      "1695  Sometimes the girls bickered and sniped at eac...       1  1696\n",
      "1696  I'm thinking of going to Somalia. Everyone the...       1  1697\n",
      "1697  The Ukrainian professor taught philosophy at t...       1  1698\n",
      "1698  He cooks dinner for his grandchildren once a w...       0  1699\n",
      "\n",
      "[1699 rows x 3 columns]\n",
      "Evaluating stereotype model...\n",
      "---------------------------------Confusion Matrix------------------------------------\n",
      "     0    1\n",
      "0  695  113\n",
      "1  135  756\n",
      "---------------------------------Evaluation Metrics------------------------------------\n",
      "              precision    recall  f1-score      support\n",
      "0              0.837349  0.860149  0.848596   808.000000\n",
      "1              0.869965  0.848485  0.859091   891.000000\n",
      "accuracy       0.854032  0.854032  0.854032     0.854032\n",
      "macro avg      0.853657  0.854317  0.853843  1699.000000\n",
      "weighted avg   0.854454  0.854032  0.854100  1699.000000\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "bias_model, bias_tokenizer = load_model(model_name, \"bias\")\n",
    "stereotype_model, stereotype_tokenizer = load_model(model_name, \"stereotype\")\n",
    "\n",
    "# Evaluate models\n",
    "for task_name, model, tokenizer in [(\"bias\", bias_model, bias_tokenizer), (\"stereotype\", stereotype_model, stereotype_tokenizer)]:\n",
    "    # Load test data\n",
    "    #Give path to test data\n",
    "    test_csv_path = \"MTL-E/dataset/StereoSet/test.csv\" if task_name=='stereotype' else \"MTL-E/dataset/ToxicBias/test.csv\"\n",
    "    test_data = load_test_data(test_csv_path)\n",
    "    print(f\"Evaluating {task_name} model...\")\n",
    "    conf_matrix, class_report = evaluate_model(model, tokenizer, test_data)\n",
    "\n",
    "    print(\"---------------------------------Confusion Matrix------------------------------------\")\n",
    "    print(pd.DataFrame(conf_matrix))\n",
    "\n",
    "    print(\"---------------------------------Evaluation Metrics------------------------------------\")\n",
    "    print(pd.DataFrame(class_report).transpose())\n",
    "        \n",
    "    # Save results to CSV\n",
    "    # result_csv_path = f\"./results/{task_name}_{model_name}_results.csv\"\n",
    "    # pd.DataFrame(class_report).transpose().to_csv(result_csv_path, index=True)\n",
    "    # print(f\"Results saved to {result_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmharness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
