{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/nlp/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import all the required libraries\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Dataset\n",
    "# StereoSet\n",
    "# ToxicBias\n",
    "dataset = 'ToxicBias'\n",
    "\n",
    "#Choose encoder model\n",
    "# bert-base-uncased\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "# Define Parameters\n",
    "learning_rate = 2e-5\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  25962\n",
      "Validation size:  2592\n",
      "Test size:  3900\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(f'Dataset/{dataset}/train.csv')\n",
    "df_val = pd.read_csv(f'Dataset/{dataset}/val.csv')\n",
    "df_test = pd.read_csv(f'Dataset/{dataset}/test.csv')\n",
    "print('Training size: ', df_train.size)\n",
    "print('Validation size: ', df_val.size)\n",
    "print('Test size: ', df_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of sentences and labels\n",
    "sentences_train = df_train.Sentence.values\n",
    "labels_train = df_train.labels.values\n",
    "sentences_val = df_val.Sentence.values\n",
    "labels_val = df_val.labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  We are still having their water put at risk in the Dakotas for some white mans profit. When white people complained about the same issue the natives were just not important enough to care about their water supply. Some of you white folks refuse to acknowledge how much you benefit from the rape robbery torture and murder done in your benefit. Many of you are quite proud in your self righteous ignorance. Or maybe you just dont think those lives matter. Or they both may be true.\n",
      "Tokenized:  ['we', 'are', 'still', 'having', 'their', 'water', 'put', 'at', 'risk', 'in', 'the', 'dakota', '##s', 'for', 'some', 'white', 'mans', 'profit', '.', 'when', 'white', 'people', 'complained', 'about', 'the', 'same', 'issue', 'the', 'natives', 'were', 'just', 'not', 'important', 'enough', 'to', 'care', 'about', 'their', 'water', 'supply', '.', 'some', 'of', 'you', 'white', 'folks', 'refuse', 'to', 'acknowledge', 'how', 'much', 'you', 'benefit', 'from', 'the', 'rape', 'robbery', 'torture', 'and', 'murder', 'done', 'in', 'your', 'benefit', '.', 'many', 'of', 'you', 'are', 'quite', 'proud', 'in', 'your', 'self', 'righteous', 'ignorance', '.', 'or', 'maybe', 'you', 'just', 'don', '##t', 'think', 'those', 'lives', 'matter', '.', 'or', 'they', 'both', 'may', 'be', 'true', '.']\n",
      "Token IDs:  [2057, 2024, 2145, 2383, 2037, 2300, 2404, 2012, 3891, 1999, 1996, 7734, 2015, 2005, 2070, 2317, 16042, 5618, 1012, 2043, 2317, 2111, 10865, 2055, 1996, 2168, 3277, 1996, 12493, 2020, 2074, 2025, 2590, 2438, 2000, 2729, 2055, 2037, 2300, 4425, 1012, 2070, 1997, 2017, 2317, 12455, 10214, 2000, 13399, 2129, 2172, 2017, 5770, 2013, 1996, 9040, 13742, 8639, 1998, 4028, 2589, 1999, 2115, 5770, 1012, 2116, 1997, 2017, 2024, 3243, 7098, 1999, 2115, 2969, 19556, 18173, 1012, 2030, 2672, 2017, 2074, 2123, 2102, 2228, 2216, 3268, 3043, 1012, 2030, 2027, 2119, 2089, 2022, 2995, 1012]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', sentences_train[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences_train[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that encode every sentence, add padding and return the input ids and attention mask\n",
    "def encode_sentences(sentences):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    # For every sentence\n",
    "    for sent in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sent,\n",
    "            add_special_tokens=True,\n",
    "            max_length=64,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        #Add the encoded sentence to list\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        #Add attention mask\n",
    "        attention_mask.append(encoded_dict['attention_mask'])\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/nlp/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  We are still having their water put at risk in the Dakotas for some white mans profit. When white people complained about the same issue the natives were just not important enough to care about their water supply. Some of you white folks refuse to acknowledge how much you benefit from the rape robbery torture and murder done in your benefit. Many of you are quite proud in your self righteous ignorance. Or maybe you just dont think those lives matter. Or they both may be true.\n",
      "Token ID:  tensor([  101,  2057,  2024,  2145,  2383,  2037,  2300,  2404,  2012,  3891,\n",
      "         1999,  1996,  7734,  2015,  2005,  2070,  2317, 16042,  5618,  1012,\n",
      "         2043,  2317,  2111, 10865,  2055,  1996,  2168,  3277,  1996, 12493,\n",
      "         2020,  2074,  2025,  2590,  2438,  2000,  2729,  2055,  2037,  2300,\n",
      "         4425,  1012,  2070,  1997,  2017,  2317, 12455, 10214,  2000, 13399,\n",
      "         2129,  2172,  2017,  5770,  2013,  1996,  9040, 13742,  8639,  1998,\n",
      "         4028,  2589,  1999,   102])\n"
     ]
    }
   ],
   "source": [
    "# Get input ids and attention mask\n",
    "train_input_ids, train_attention_mask = encode_sentences(sentences_train)\n",
    "val_input_ids, val_attention_mask = encode_sentences(sentences_val)\n",
    "\n",
    "#Convert the list into tensors\n",
    "train_input_ids = torch.cat(train_input_ids, dim=0)\n",
    "train_attention_mask = torch.cat(train_attention_mask, dim=0)\n",
    "labels_train = torch.tensor(labels_train)\n",
    "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
    "val_attention_mask = torch.cat(val_attention_mask, dim=0)\n",
    "labels_val = torch.tensor(labels_val)\n",
    "\n",
    "#Print sentence 0 \n",
    "print('Original: ', sentences_train[0])\n",
    "print('Token ID: ', train_input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_mask, labels_train)\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_mask, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create a DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler=RandomSampler(train_dataset),\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler=SequentialSampler(val_dataset),\n",
    "            batch_size=batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/nlp/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=learning_rate,\n",
    "                  eps=1e-8\n",
    "                  )\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format time\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store training and validation loss\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "Batch    40 of   136. Elapsed: 0:00:04.\n",
      "Batch    80 of   136. Elapsed: 0:00:07.\n",
      "Batch   120 of   136. Elapsed: 0:00:11.\n",
      "Average training loss: 0.48\n",
      "Training epoch took: 0:00:12\n",
      "Running Validation...\n",
      "Accuracy: 0.81\n",
      "Validation Loss: 0.44\n",
      "Validation took: 0:00:00\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "Batch    40 of   136. Elapsed: 0:00:03.\n",
      "Batch    80 of   136. Elapsed: 0:00:07.\n",
      "Batch   120 of   136. Elapsed: 0:00:10.\n",
      "Average training loss: 0.40\n",
      "Training epoch took: 0:00:11\n",
      "Running Validation...\n",
      "Accuracy: 0.82\n",
      "Validation Loss: 0.43\n",
      "Validation took: 0:00:00\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "Batch    40 of   136. Elapsed: 0:00:03.\n",
      "Batch    80 of   136. Elapsed: 0:00:07.\n",
      "Batch   120 of   136. Elapsed: 0:00:10.\n",
      "Average training loss: 0.31\n",
      "Training epoch took: 0:00:11\n",
      "Running Validation...\n",
      "Accuracy: 0.84\n",
      "Validation Loss: 0.45\n",
      "Validation took: 0:00:00\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "Batch    40 of   136. Elapsed: 0:00:03.\n",
      "Batch    80 of   136. Elapsed: 0:00:07.\n",
      "Batch   120 of   136. Elapsed: 0:00:10.\n",
      "Average training loss: 0.23\n",
      "Training epoch took: 0:00:11\n",
      "Running Validation...\n",
      "Accuracy: 0.81\n",
      "Validation Loss: 0.47\n",
      "Validation took: 0:00:00\n",
      "Training complete!\n",
      "Total training took 0:00:46 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "# For each epoch\n",
    "for epoch in range(epochs):\n",
    "    # TRAINING\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('Batch {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from dataloader.\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Clear any previously calculated gradients before performing a backward pass.\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass\n",
    "        loss, logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels, return_dict=False)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print('Average training loss: {0:.2f}'.format(avg_train_loss))\n",
    "    print('Training epoch took: {:}'.format(training_time))\n",
    "\n",
    "    # VALIDATION\n",
    "    print('Running Validation...')\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            (loss, logits) = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels, return_dict=False)\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    \n",
    "    # Average validation accuracy\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print('Accuracy: {0:.2f}'.format(avg_val_accuracy))\n",
    "\n",
    "    # Average loss over all the batches\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Measure how long the validation run took\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print('Validation Loss: {0:.2f}'.format(avg_val_loss))\n",
    "    print('Validation took: {:}'.format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print('Training complete!')\n",
    "print('Total training took {:} (h:mm:ss)'.format(format_time(time.time() - total_t0)))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0:00:12</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0:00:11</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0:00:11</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0:00:11</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.48         0.44           0.81       0:00:12         0:00:00\n",
       "2               0.40         0.43           0.82       0:00:11         0:00:00\n",
       "3               0.31         0.45           0.84       0:00:11         0:00:00\n",
       "4               0.23         0.47           0.81       0:00:11         0:00:00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmharness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
