{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the required libraries\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Dataset\n",
    "# StereoSet\n",
    "# ToxicBias\n",
    "dataset = 'StereoSet'\n",
    "dataset_type = 'Stereotype'\n",
    "\n",
    "# BERT large    ----> bert-large-uncased\n",
    "# ALBERT large  ----> albert-xxlarge-v2\n",
    "# RoBERTa large ----> roberta-large\n",
    "model_name = 'roberta-large'\n",
    "\n",
    "# Define Parameters\n",
    "learning_rate = 2e-5\n",
    "epochs = 4\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (6113, 2)\n",
      "Validation shape:  (680, 2)\n",
      "Test shape:  (1699, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(f'Dataset/{dataset}/train.csv')\n",
    "df_val = pd.read_csv(f'Dataset/{dataset}/val.csv')\n",
    "df_test = pd.read_csv(f'Dataset/{dataset}/test.csv')\n",
    "print('Training shape: ', df_train.shape)\n",
    "print('Validation shape: ', df_val.shape)\n",
    "print('Test shape: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6113\n",
      "Stereotype instances in training data:  labels\n",
      "0    3098\n",
      "1    3015\n",
      "Name: count, dtype: int64\n",
      "Stereotype instances in validation data:  labels\n",
      "0    340\n",
      "1    340\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List of sentences and labels\n",
    "sentences_train = df_train.Sentence.values\n",
    "labels_train = df_train.labels.values\n",
    "sentences_val = df_val.Sentence.values\n",
    "labels_val = df_val.labels.values\n",
    "\n",
    "print(len(df_train['labels']))\n",
    "\n",
    "print(f\"{dataset_type} instances in training data: \", df_train[\"labels\"].value_counts())\n",
    "print(f\"{dataset_type} instances in validation data: \", df_val[\"labels\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  The schoolboy has some young qualities about him. Young qualities are usually producing charming people.\n",
      "Tokenized:  ['the', 'school', '##boy', 'has', 'some', 'young', 'qualities', 'about', 'him', '.', 'young', 'qualities', 'are', 'usually', 'producing', 'charming', 'people', '.']\n",
      "Token IDs:  [1996, 2082, 11097, 2038, 2070, 2402, 11647, 2055, 2032, 1012, 2402, 11647, 2024, 2788, 5155, 11951, 2111, 1012]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', sentences_train[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences_train[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that encode every sentence, add padding and return the input ids and attention mask\n",
    "def encode_sentences(sentences):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    # For every sentence\n",
    "    for sent in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sent,\n",
    "            add_special_tokens=True,\n",
    "            max_length=64,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        #Add the encoded sentence to list\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        #Add attention mask\n",
    "        attention_mask.append(encoded_dict['attention_mask'])\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/nlp/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  The schoolboy has some young qualities about him. Young qualities are usually producing charming people.\n",
      "Token ID:  tensor([  101,  1996,  2082, 11097,  2038,  2070,  2402, 11647,  2055,  2032,\n",
      "         1012,  2402, 11647,  2024,  2788,  5155, 11951,  2111,  1012,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# Get input ids and attention mask\n",
    "train_input_ids, train_attention_mask = encode_sentences(sentences_train)\n",
    "val_input_ids, val_attention_mask = encode_sentences(sentences_val)\n",
    "\n",
    "#Convert the list into tensors\n",
    "train_input_ids = torch.cat(train_input_ids, dim=0)\n",
    "train_attention_mask = torch.cat(train_attention_mask, dim=0)\n",
    "labels_train = torch.tensor(labels_train)\n",
    "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
    "val_attention_mask = torch.cat(val_attention_mask, dim=0)\n",
    "labels_val = torch.tensor(labels_val)\n",
    "\n",
    "#Print sentence 0 \n",
    "print('Original: ', sentences_train[0])\n",
    "print('Token ID: ', train_input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_mask, labels_train)\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_mask, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler=RandomSampler(train_dataset),\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler=SequentialSampler(val_dataset),\n",
    "            batch_size=batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/nlp/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=learning_rate,\n",
    "                  eps=1e-8\n",
    "                  )\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format time\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "Batch    40 of   192. Elapsed: 0:00:10.\n",
      "Batch    80 of   192. Elapsed: 0:00:21.\n",
      "Batch   120 of   192. Elapsed: 0:00:31.\n",
      "Batch   160 of   192. Elapsed: 0:00:42.\n",
      "Average training loss: 0.57\n",
      "Training epoch took: 0:00:50\n",
      "Running Validation...\n",
      "Accuracy: 0.81\n",
      "Validation Loss: 0.44\n",
      "Validation took: 0:00:02\n",
      "0.8027346963517177\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.82    0.77      0.80    340.0\n",
      "1                  0.78    0.84      0.81    340.0\n",
      "accuracy           0.80    0.80      0.80      0.8\n",
      "macro avg          0.80    0.80      0.80    680.0\n",
      "weighted avg       0.80    0.80      0.80    680.0\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "Batch    40 of   192. Elapsed: 0:00:10.\n",
      "Batch    80 of   192. Elapsed: 0:00:21.\n",
      "Batch   120 of   192. Elapsed: 0:00:31.\n",
      "Batch   160 of   192. Elapsed: 0:00:42.\n",
      "Average training loss: 0.33\n",
      "Training epoch took: 0:00:50\n",
      "Running Validation...\n",
      "Accuracy: 0.85\n",
      "Validation Loss: 0.40\n",
      "Validation took: 0:00:02\n",
      "0.8528788154148385\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.84    0.87      0.86   340.00\n",
      "1                  0.87    0.83      0.85   340.00\n",
      "accuracy           0.85    0.85      0.85     0.85\n",
      "macro avg          0.85    0.85      0.85   680.00\n",
      "weighted avg       0.85    0.85      0.85   680.00\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "Batch    40 of   192. Elapsed: 0:00:10.\n",
      "Batch    80 of   192. Elapsed: 0:00:21.\n",
      "Batch   120 of   192. Elapsed: 0:00:31.\n",
      "Batch   160 of   192. Elapsed: 0:00:42.\n",
      "Average training loss: 0.15\n",
      "Training epoch took: 0:00:50\n",
      "Running Validation...\n",
      "Accuracy: 0.88\n",
      "Validation Loss: 0.37\n",
      "Validation took: 0:00:02\n",
      "0.8852901484480432\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.88    0.89      0.89   340.00\n",
      "1                  0.89    0.88      0.88   340.00\n",
      "accuracy           0.89    0.89      0.89     0.89\n",
      "macro avg          0.89    0.89      0.89   680.00\n",
      "weighted avg       0.89    0.89      0.89   680.00\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "Batch    40 of   192. Elapsed: 0:00:10.\n",
      "Batch    80 of   192. Elapsed: 0:00:21.\n",
      "Batch   120 of   192. Elapsed: 0:00:31.\n",
      "Batch   160 of   192. Elapsed: 0:00:42.\n",
      "Average training loss: 0.07\n",
      "Training epoch took: 0:00:50\n",
      "Running Validation...\n",
      "Accuracy: 0.88\n",
      "Validation Loss: 0.41\n",
      "Validation took: 0:00:02\n",
      "0.8896865584152933\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.88    0.90      0.89   340.00\n",
      "1                  0.90    0.88      0.89   340.00\n",
      "accuracy           0.89    0.89      0.89     0.89\n",
      "macro avg          0.89    0.89      0.89   680.00\n",
      "weighted avg       0.89    0.89      0.89   680.00\n",
      "Training complete!\n",
      "Total training took 0:03:33 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "# To store training and validation loss\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(epochs):\n",
    "    # TRAINING\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('Batch {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from dataloader.\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Clear any previously calculated gradients before performing a backward pass.\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass\n",
    "        loss, logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels, return_dict=False)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print('Average training loss: {0:.2f}'.format(avg_train_loss))\n",
    "    print('Training epoch took: {:}'.format(training_time))\n",
    "\n",
    "    # VALIDATION\n",
    "    print('Running Validation...')\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Predictions list and true labels list\n",
    "    (predictions, true_labels) = ([], [])\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            (loss, logits) = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels, return_dict=False)\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    \n",
    "    # Average validation accuracy\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print('Accuracy: {0:.2f}'.format(avg_val_accuracy))\n",
    "\n",
    "    # Average loss over all the batches\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Measure how long the validation run took\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print('Validation Loss: {0:.2f}'.format(avg_val_loss))\n",
    "    print('Validation took: {:}'.format(validation_time))\n",
    "\n",
    "    # get the predictions and true labels in form of list\n",
    "    (pred_list, true_list) = ([], [])\n",
    "    for i in range(len(true_labels)):\n",
    "        pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "        pred_list.extend(list(pred_labels_i))\n",
    "        true_list.extend(list(true_labels[i]))\n",
    "\n",
    "    # Print classification report\n",
    "    f1_score = classification_report(true_list, pred_list, output_dict=True)\n",
    "    print(f1_score['weighted avg']['f1-score'])\n",
    "    print(pd.DataFrame(f1_score).transpose())\n",
    "\n",
    "    # Record all statistics from this epoch\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch + 1,\n",
    "            'f1-score': f1_score['weighted avg']['f1-score'],\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "    model.save_pretrained(f'Models/{model_name}/{dataset}/{epoch}.pt')\n",
    "\n",
    "print('Training complete!')\n",
    "print('Total training took {:} (h:mm:ss)'.format(format_time(time.time() - total_t0)))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0:00:50</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0:00:50</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0:00:50</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0:00:50</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1-score  Training Loss  Valid. Loss  Valid. Accur. Training Time  \\\n",
       "epoch                                                                      \n",
       "1          0.80           0.57         0.44           0.81       0:00:50   \n",
       "2          0.85           0.33         0.40           0.85       0:00:50   \n",
       "3          0.89           0.15         0.37           0.88       0:00:50   \n",
       "4          0.89           0.07         0.41           0.88       0:00:50   \n",
       "\n",
       "      Validation Time  \n",
       "epoch                  \n",
       "1             0:00:02  \n",
       "2             0:00:02  \n",
       "3             0:00:02  \n",
       "4             0:00:02  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats.to_csv(f'Models/{model_name}/{dataset}/stats.csv')\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model on Test data\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "test_model_name = 'roberta-large'\n",
    "test_dataset = 'StereoSet'\n",
    "test_model_number = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/data/nlp/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed  0\n",
      "Completed  100\n",
      "Completed  200\n",
      "Completed  300\n",
      "Completed  400\n",
      "Completed  500\n",
      "Completed  600\n",
      "Completed  700\n",
      "Completed  800\n",
      "Completed  900\n",
      "Completed  1000\n",
      "Completed  1100\n",
      "Completed  1200\n",
      "Completed  1300\n",
      "Completed  1400\n",
      "Completed  1500\n",
      "Completed  1600\n"
     ]
    }
   ],
   "source": [
    "# Import model\n",
    "model_path = f'Models/{test_model_name}/{test_dataset}/{test_model_number}.pt'\n",
    "test_model = AutoModelForSequenceClassification.from_pretrained(model_path, output_attentions=True)\n",
    "\n",
    "# Import tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(test_model_name, do_lower_case=True)\n",
    "\n",
    "# Load test data\n",
    "\n",
    "df_test = pd.read_csv(f'Dataset/{test_dataset}/test.csv')\n",
    "\n",
    "# Store predicted and true labels and sentences\n",
    "(test_sentences, test_predicted_labels, test_true_labels) = ([], [], [])\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    sentence = df_test['Sentence'][i]\n",
    "    label = df_test['labels'][i]\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sentence,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = test_model(input_ids, token_type_ids=None, attention_mask=attention_mask, return_dict=True)\n",
    "        logits = output.logits\n",
    "        \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    pred_label = np.argmax(logits, axis=1).flatten()\n",
    "    test_sentences.append(sentence)\n",
    "    test_predicted_labels.append(pred_label)\n",
    "    test_true_labels.append(label)\n",
    "    if(i%100 == 0):\n",
    "        print('Completed ', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88       808\n",
      "           1       0.89      0.88      0.89       891\n",
      "\n",
      "    accuracy                           0.88      1699\n",
      "   macro avg       0.88      0.88      0.88      1699\n",
      "weighted avg       0.88      0.88      0.88      1699\n",
      "\n",
      "[[713  95]\n",
      " [104 787]]\n"
     ]
    }
   ],
   "source": [
    "# get classification report\n",
    "f1_score = classification_report(test_true_labels, test_predicted_labels)\n",
    "print(f1_score)\n",
    "\n",
    "# get confusion matrix\n",
    "conf_matrix = confusion_matrix(test_true_labels, test_predicted_labels)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmharness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
